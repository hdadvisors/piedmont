---
title: "Piedmont Housing Alliance Data Analysis"
format:
  html:
    toc: true
    toc-location: left
    number-sections: true
    theme: flatly
    author: "Jonathan Knopf (jonathan@hdadvisors.net)"
execute: 
  echo: true
  warning: false
  freeze: auto
code-fold: true
code-overflow: scroll
---

```{r}
#| label: setup
#| code-summary: "Setup code"

# Load data management and analysis tools

library(tidyverse)
library(tidycensus)
library(readxl)
library(janitor)
library(lubridate)

# Load data visualization tools

library(hdatools)
library(scales)
library(ggiraph)
library(ggtext)
library(ggridges)
library(kableExtra)
library(reactable)
library(patchwork)
library(formattable)

# Set defaults

setwd("~/repos/piedmont")

today <- Sys.Date()

showtext::showtext_opts(dpi = 150)

```

::: {.callout-warning}
## Please note
This document is still under construction. It was last updated `r format(today, format = "%B %d, %Y")` at `r format(Sys.time(), "%I:%M %p")`.
:::

# About

Piedmont Housing Alliance (PHA) is a 501(c)3 nonprofit organization that provides housing services to clients in the Charlottesville, Virginia region. In 2022, PHA received a Tier III Capacity Building Program Enhancement Grant from Virginia Housing to evaluate and improve their programs aimed at helping first-time homebuyers.

::: {.callout-note}
## How PHA helps first-time homebuyers

PHA offers two programs to help buyers earning less than 80% of Area Median Income (AMI) purchase their first home.

1. The **Down Payment Loan** (DPL) program combines funding from several different sources to provide buyers with additional assistance to increase their total down payment and cover closing costs. This allows buyer to more easily afford homes at prices they would otherwise be unable to afford.

2. PHA administers the **Sponsoring Partnerships & Revitalizing Communities** (SPARC) program, which lowers a buyer's mortgage interest rate by 1.00%. SPARC funds are allocated by Virginia Housing and help buyers save thousands of dollars over the life of their loan.
:::

PHA seeks a deeper understanding of these two programs' outcomes and impacts, particularly in terms of racial equity and wealth-building. This document was prepared by HDAdvisors to develop methods for evaluating the program using internal and external data.

## Goals

The primary goal of this analysis is a preliminary evaluation of the DPL and SPARC programs' current abilities to support buyers who are more likely to be at a systemic disadvantage because of unjust lending practices and other discriminatory efforts.

The secondary goal is to provide PHA staff with reproducible methods for collecting, preparing, and analyzing the data necessary for this evaluation. This will allow PHA to regularly track and monitor these programs without outside assistance.

::: {.callout-note}
## Why this matters

This analysis will be helpful for PHA in three important ways:

1. To proactively assess whether the program fulfills all applicable fair housing requirements,
2. To provide staff with a thorough understanding of program outcomes for stronger grant applications, and
3. To further PHA's existing Diversity, Equity, and Inclusion (DEI) efforts.
:::

## Guiding questions

The following questions help determine (1) what kind of data is needed, and (2) how that data should be analyzed.

* How do PHA's clients vary by race, ethnicity, and income compared to the region as a whole?
* Do the levels of assistance vary significantly by race, ethnicity, and income?
* Are there noticeable migration patterns for clients purchasing their first home?
* How do the homes purchased by clients compare to similar homes in that neighborhood?
* How much home equity have past clients gained? How similar are these gains across race, ethnicity, and neighborhoods?

# Data assembly

This section outlines each metric necessary for analysis, along with methods for collecting and cleaning the appropriate data.

## Program and client data

PHA provided data on DPL and SPARC clients from FY 2018 through FY 2023.

This data includes attributes about each client household, including:

* Total annual income
* Area median income (AMI)
* Race and ethnicity (optional)
* Number of persons
* Street address (at time of application)

It also includes DPL-specific program data, including:

* Number of loans provided
* Total amount of DPL assistance
* Funding sources used for each loan
* Source(s) and amount of non-DPL assistance

Information on the homes purchased by clients include:

* Street address
* Sales price
* Appraised value
* Closing costs and other prepaids

Information about clients' mortgages are also provided:

* Lending institution
* Mortgage product
* Mortgage amount
* Interest rate
* Original interest rate (SPARC only)
* Closing date

The full dataset includes multiple other fields that are not necessary or relevant to this analysis.

**Step 1: Import data**

```{r}
#| label: data-import
#| code-summary: "Client data import"

# Import list of DPL clients and clean column names

clients_dpl_raw <- read_xlsx("data/raw/clients.xlsx",
                             sheet = "Down Payment Loan") |> 
  clean_names()
  

# Import list of SPARC clients and clean column names

clients_sparc_raw <- read_xlsx("data/raw/clients.xlsx",
                             sheet = "SPARC") |> 
  clean_names()

```

**Step 2: Clean up and fix data**

```{r}
#| label: dpl-data-prep
#| code-summary: "DPL client data prep"

# Clean up DPL data

clients_dpl <- clients_dpl_raw |> 
  
  # Drop rows that do not have client records
  
  drop_na(contract_date) |>
  
  # Remove columns with personal information or unnecessary data
  
  select(!c(fha_case_number, ami_approval_date, client_intake_date,
            client_last_name, client_first_name, counselor,
            service_type, client_employer, employer_msa,
            property_msa, status, loan_officer, client_msa,
            client_email_address, phone_number
            )) |> 
  
  # Rename certain columns to more helpful descriptions
  
  rename(mortgage_product = x1st_mortgage_product,
         mortgage_amount = x1st_mortgage_amount,
         pha_loans_n = number_of_pha_loans,
         pha_loans_amount = of_pha_loans,
         pha_loan_source = source_of_pha_loan
         ) |> 
  
  # Create new unique DPL client ID column
  
  mutate(id_dpl = str_c("DPL", str_pad(row_number(), 3, pad = "0")),
         .before = 1) |> 
  
  # Clean up original client_number column
  
  mutate(client_number = str_remove_all(client_number, "\\.0")) |> 
  
  # Change "Unknown" values to NA in appraised_value
  
  mutate(appraised_value = as.numeric(na_if(appraised_value, "Unknown"))) |> 
  
  # Clean up lending_institution names

  mutate(lending_institution = case_when(
    str_detect(lending_institution, "Coast") ~ "Atlantic Coast Mortgage",
    str_detect(lending_institution, "Fulton") ~ "Fulton Mortgage",
    str_detect(lending_institution, "Charlottesville") ~ "Habitat for Humanity of Greater Charlottesville",
    str_detect(lending_institution, regex("first", ignore_case = T)) ~ "Towne First Mortgage",
    str_detect(lending_institution, "USDA") ~ "USDA",
    str_detect(lending_institution, "Waterstone") ~ "Waterstone Mortgage Corporation",
    lending_institution == "Towne Bank Mortgage" ~ "TowneBank Mortgage",
    TRUE ~ lending_institution
  )) |> 
  
  # Clean up mortgage_product names
  
  mutate(mortgage_product = case_when(
    str_detect(mortgage_product, "502|USDA|RHS") ~ "502 Direct Loan",
    mortgage_product == "Coventional" ~ "Conventional",
    str_detect(mortgage_product, "VHDA FHA|VHDA - HFA") ~ "VHDA - FHA",
    TRUE ~ mortgage_product
  )) |> 
  
  # Change '$-' values in other_assistance_amount to NA
  
  mutate(other_assistance_amount = as.numeric(na_if(other_assistance_amount, "$-"))) |> 
  
  # Create column for single or multiple race; clean up race names
  
  mutate(multirace = case_when(
      str_detect(race, "Multi") ~ "Multiple",
      TRUE ~ "Single"),
    .before = race) |> 
  
  mutate(race = case_when(
    str_detect(race, "and White") ~ "Black and White",
    str_detect(race, "Other") ~ "Other races",
    str_detect(race, "Asian") ~ "Asian",
    str_detect(race, "Single Race - Black") ~ "Black",
    TRUE ~ "White"
  )) |> 
  
  # Simplify rural_area_status and english_proficiency columns
  
  mutate(rural_area_status = case_when(
    str_detect(rural_area_status, "lives") ~ "Rural",
    TRUE ~ "Not rural"
  )) |> 
  
  mutate(english_proficiency = case_when(
    str_detect(english_proficiency, "is not") ~ "Not proficient",
    TRUE ~ "Proficient"
  ))

```

```{r}
#| label: sparc-data-prep
#| code-summary: "SPARC client data prep"

# Clean up SPARC data

clients_sparc <- clients_sparc_raw |> 
  
  # Remove columns with personal information or unnecessary data
  
  select(!c(last_name, first_name, client,
            lenders_name, x20)) |> 
  
  # Rename certain columns to match DPL data
  
  rename(sale_price = sales_price,
         mortgage_amount = base_loan_amount,
         household_annual_income = borrower_s_income,
         household_size = number_in_hh,
         locality = msa,
         mortgage_product = loan_product,
         lending_institution = lending_company
         ) |> 
  
  # Change client_number column to string
  
  mutate(client_number = as.character(client_number)) |> 
  
  # Create new unique SPARC client ID column
  
  mutate(id_sparc = str_c("SPC", str_pad(row_number(), 3, pad = "0")),
         .before = 1) |> 
  
  # Fix interest_rate values
  
  mutate(interest_rate = case_when(
    interest_rate > 1 ~ interest_rate/100,
    TRUE ~ interest_rate
  )) |> 
  
  # Create mortgage_notes column for specific loan info
  
  mutate(mortgage_notes = case_when(
    str_detect(mortgage_product, "No MI") ~ "No mortgage insurance",
    str_detect(mortgage_product, "Reduced") ~ "Reduced mortgage insurance",
    str_detect(mortgage_product, "Second Plus") ~ "Second Plus",
    TRUE ~ NA_character_),
    .after = mortgage_product
    ) |> 
  
  # Clean up mortgage_product names to match DPL data
  
  mutate(mortgage_product = case_when(
    str_detect(mortgage_product, regex("Conventional", ignore_case = T)) ~ "Conventional",
    str_detect(mortgage_product, regex("RHS", ignore_case = T)) ~ "502 Direct Loan",
    str_detect(mortgage_product, regex("FHA", ignore_case = T)) ~ "FHA",
    is.na(mortgage_product) ~ "Unknown",
    TRUE ~ mortgage_product
  )) |> 
  
  # Clean up lending_institution names to match DPL data

  mutate(lending_institution = case_when(
    str_detect(lending_institution, "C&F") ~ "C&F Mortgage Corporation",
    str_detect(lending_institution, "Waterstone") ~ "Waterstone Mortgage Corporation",
    is.na(lending_institution) ~ "Unknown",
    TRUE ~ lending_institution
  )) |> 
  
  # Clean up yes/no columns
  
  mutate(received_cd = case_when(
    str_detect(received_cd, "YES|Yes|yes") ~ "Yes",
    received_cd == "no" ~ "No",
    received_cd == "N/A" ~ NA_character_,
    TRUE ~ NA_character_
  )) |> 
  
  mutate(in_ors = case_when(
    str_detect(in_ors, "No -") ~ "No",
    TRUE ~ in_ors
  ))

```

**Step 3: Join DPL and SPARC client data**

Some clients use both the DPL and SPARC programs to purchase their home. For now, these clients were identified by manually cross-referencing names and other fields. To join the data, the DPL `client_number` values were assigned to the respective client records in the SPARC data.

In the future, PHA should maintain a single client dataset that can differentiate between DPL-only, SPARC-only, and "double-dipping" clients. Specific recommendations will be detailed at the end of this document.

```{r}
#| label: data-join
#| code-summary: "Client data join"

# Create full join using client_number

clients_all <- clients_dpl |> 
  full_join(clients_sparc, by = "client_number", na_matches = "never",
            suffix = c("_dpl", "_spc")) |> 
  
  # Reorder columns to place duplicate fields together
  
  select(2, 1, 46, 3, 4, 47, 5, 52, 6, 7, 53, 8, 9,
         10, 11, 12, 13, 14, 50, 15, 16, 17, 59, 18,
         55, 19, 51, 20, 49, 48, 50, 21, 22, 23, 24,
         25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 54,
         56, 57, 60, 61
         ) |> 
  
  # Create column to show whether client uses one or both programs
  
  mutate(program = case_when(
      !is.na(id_dpl) & !is.na(id_sparc) ~ "Both",
      !is.na(id_dpl) & is.na(id_sparc) ~ "DPL",
      TRUE ~ "SPARC"),
    .before = 1) |> 
  
  # Create universal client ID column
  
  mutate(id_pha = str_c("PHA", str_pad(row_number(), 3, pad = "0")),
         .before = 1)

```

**Step 4: View data**

Cleaned and joined client data are shown in the table below.

```{r}
#| label: dpl-table
#| code-summary: "Generate table"

reactable(clients_all,
          defaultPageSize = 5,
          defaultColDef = colDef(minWidth = 150),
          compact = TRUE,
          striped = TRUE,
          wrap = FALSE)

```

Where there were duplicate fields from each dataset, the `_dpl` and `_spc` suffixes were added to the end of column names, respective to their source. For example, the close date data from the DPL records are retained as the `close_date_dpl` column, while the close dates from the SPARC data are `close_date_spc`.

::: {.callout-warning}
## Data integrity issues
Both the DPL and SPARC datasets were found to have data integrity issues that PHA should resolve in the future.

* Mortgage product fields included both "RHS" (Rural Housing Service), "USDA", and "502" values. For now, these are all assumed to be "502 Direct Loans".

* Overlapping fields from the DPL and SPARC datasets do not always reconcile for the clients who used both programs. For example, the specific close dates and household income values are often slightly different---but should, in theory, be identical.

* The SPARC client records are missing many values in the closing date, interest rate, household income, household size, and lender columns.

* Some DPL clients were noted as receiving SPARC in the `other_assistance` column. However, two of clients were *not* found in the SPARC data.
:::

## Regional and neighborhood profiles

::: {.callout-tip}
### Why this is needed

Demographic and socioeconomic data will help establish the baseline characteristics of population groups that PHA seeks to compare with its clients. For example, how closely does the client pool match the average racial and ethnic makeup across the region?
:::

Two datasets will be used to create summary profiles of the geographies PHA will use as reference for its clients' characteristics. Both are from the U.S. Census Bureau:

* 2020 Decennial Census
* American Community Survey (5-year estimates)

::: {.callout-note}
As of `r format(today, format = "%B %Y")`, the latest ACS data available are the 2017-2021 5-year estimates.
:::

The fields to collect from this data include:

* Race and ethnicity of population
* Average household incomes
* Homeownership rates

**Step 1: Race and ethnicity data from 2020 Census**

```{r}
#| label: acs-race-import
#| code-summary: "Import data"

# Get variables for 2020 Census PL-94171 Redistricting dataset

pl_vars <- load_variables(2020, "pl")

# Find and select race and ethnicity variables

race_vars <- pl_vars |> 
  filter(name %in% c(
    "P1_003N", # White
    "P1_004N", # Black
    "P1_005N", # American Indian and Alaska Native
    "P1_006N", # Asian
    "P1_007N", # Native Hawaiian and Other Pacific Islander
    "P1_008N", # Some other race
    "P1_009N", # Two or more races
    "P2_002N", # Total Hispanic or Latino
    "P2_003N"  # Total not Hispanic or Latino
  )) |> 
  
  # Rename race and ethnicity groups 
  
  mutate(label = case_when(
    name == "P1_003N" ~ "White",
    name == "P1_004N" ~ "Black",
    name == "P1_005N" ~ "Another race",
    name == "P1_006N" ~ "Asian",
    name == "P1_007N" ~ "Another race",
    name == "P1_008N" ~ "Another race",
    name == "P1_009N" ~ "Multiracial",
    name == "P2_002N" ~ "Hispanic or Latino",
    name == "P2_003N" ~ "Not Hispanic or Latino",
  )) |> 
  
  # Add race/ethnicity label
  
  mutate(category = case_when(
      str_detect(name, "P1") ~ "Race",
      TRUE ~ "Ethnicity"),
    .after = 1
  ) |> 
  
  # Drop concept column (unneeded)
  
  select(-concept)

# Import 2020 Census race and ethnicity data for Charlottesville City

cv_race_raw <- get_decennial(
  geography = "county",
  variables = race_vars$name,
  year = 2020,
  sumfile = "pl",
  state = "VA",
  county = "Charlottesville city"
)

```

```{r}
#| label: acs-race-prep
#| code-summary: "Prep data"

# Join race and ethnicity labels

cv_race <- cv_race_raw |> 
  left_join(race_vars, by = c("variable" = "name")) |> 
  
  # Sum "Another race" values into one row
  
  group_by(category, label) |> 
  summarise(value = sum(value)) |> 
  
  # Add percent column
  
  group_by(category) |> 
  mutate(pct = value/sum(value)) |> 
  ungroup()

# Generate table

cv_race |> 
  arrange(desc(value), .by_group = TRUE) |> 
  kable() |> 
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  )

```

**Step 2: Household income data from ACS**

```{r}
#| label: acs-inc-import
#| code-summary: "Import data"

# Get variables for Table B25118: Tenure by Household Income

b25118_vars <- load_variables(2021, "acs5") |> 
  filter(str_sub(name, end = 6) %in% "B25118")

# Clean variables

inc_vars <- b25118_vars |> 
  separate(label, c("est", "total", "tenure", "income"), sep = "!!") |> 
  select(1, 4, 5) |> 
  drop_na() |> 
  mutate(tenure = str_remove_all(tenure, " occupied:"),
         tenure = str_replace_all(tenure, "Owner", "Homeowner"))

# Import 2021 ACS estimates

b25118_raw <- get_acs(
  geography = "county",
  variables = inc_vars$name,
  year = 2021,
  county = "Charlottesville city",
  state = "VA"
)

```

```{r}
#| label: acs-inc-prep
#| code-summary: "Prep data"

# Join variables to data

cv_income <- b25118_raw |> 
  left_join(inc_vars, by = c("variable" = "name")) |> 
  
  # Remove unnecessary columns and rearrange
  
  select(6, 7, 4) |> 
  
  # Collapse into fewer income categories
  
  mutate(income = case_when(
    income == "Less than $5,000" ~ "Less than $35,000",
    income == "$5,000 to $9,999" ~ "Less than $35,000",
    income == "$10,000 to $14,999" ~ "Less than $35,000",
    income == "$15,000 to $19,999" ~ "Less than $35,000",
    income == "$20,000 to $24,999" ~ "Less than $35,000",
    income == "$25,000 to $34,999" ~ "Less than $35,000",
    income == "$100,000 to $149,999" ~ "$100,000 or more",
    income == "$150,000 or more" ~ "$100,000 or more",
    TRUE ~ income
  )) |> 
  group_by(tenure, income) |> 
  summarise(estimate = sum(estimate))

# Generate table

cv_income |> 
  ungroup() |> 
  mutate(income = fct_relevel(income, "Less than $35,000", "$35,000 to $49,999",
                              "$50,000 to $74,999", "$75,000 to $99,999",
                              "$100,000 or more")) |> 
  arrange(income) |> 
  kable() |> 
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  )

```

**Step 3: Homeownership data from ACS**

```{r}
#| label: acs-tenure-import
#| code-summary: "Import data"

# tbd

```

```{r}
#| label: acs-tenure-prep
#| code-summary: "Prep data"

# tbd

```

## Mortgage applications and activity

::: {.callout-tip}
### Why this is needed

Along with comparing client characteristics with the region or a neighborhood as a whole, we can compare their mortgages to overall lending activity in the community over time. This will allow PHA to benchmark its buyer assistance efforts to home loan trends across the region.
:::

This information is available from the Home Mortgage Disclosure Act (HMDA) data from the Consumer Financial Protection Bureau. HMDA data include loan-level information on buyer demographics, loan attributes, and property characteristics. Entries for buyers whose applications were eventually withdrawn or denied are also included.

::: {.callout-note}
As of `r format(today, format = "%B %Y")`, the latest HMDA data available is for 2021.
:::

The fields to collect from this data include:

* Buyer race and ethnicity
* Buyer county and census tract
* Loan type (conventional, FHA, VA, or USDA)
* Action taken (loan originated, application denied or withdrawn)
* Loan amount
* Interest rate
* Property value
* Occupancy type (principal residence only)
* Buyer gross annual income
* Debt-to-income ratio

`Add steps on cleaning/preparing this data`

## Home values

::: {.callout-tip}
### Why this is needed

Detailed data on home sales and values are necessary to make estimates about the total home equity gained (or lost) by PHA buyers and other homeowners in the community. This property-level data will help PHA assess its programs' abilities to support wealth-building among clients.
:::

### Real estate assessments

Localities in PHA's service area regularly assess property values to calculate the total real estate taxes to be paid by each property owner. Properties are reassessed to better match taxable values with potential market values, which can change significantly over time.

Despite these updates, local assessments can often lag behind current market trends, so they are not the most accurate indicator of the actual market value of a home if it were sold. Still, assessment data are consistent and publicly available for all parcels in a locality. This creates a useful longitudinal dataset.

For this preliminary analysis, only assessment data from the City of Charlottesville will be used.

The fields to collect from this data include:

* Parcel number
* Street number and name
* Bedrooms and bathrooms
* Finished square footage
* Total assessed value

`Add steps on cleaning/preparing this data`

### MLS sales

Actual recorded home sales are the most accurate way to determine residential property values. For arms-length transactions, sales prices reflect the actual market value of each home. These records are therefore the ideal source to best determine home equity changes among homeowners.

PHA is able to provide data exported from the multiple listing service (MLS) operated by the Charlottesville Area Association of REALTORSÂ® (CAAR). The MLS platform includes all real estate listings from agents in the region and is dynamically updated as listings are added, updated, or closed.

For this preliminary analysis, PHA has provided data on all sold single-family homes in the City of Charlottesville from September 2022 through November 22, 2022.

Fields included in this exports include:

* Property address
* Days on market
* List price
* Closed date
* Bedrooms and bathrooms
* Finished square footage

`Add steps on cleaning/preparing this data`

## Other data

`May or may not eventually be used` 

* Neighborhood boundaries from City of Charlottesville ([link](https://opendata.charlottesville.org/datasets/charlottesville::planning-neighborhood-area/about))
* Real estate sales ([link](https://opendata.charlottesville.org/maps/real-estate-sales))

# Analysis

## Clients served by program

From July 2017 through September 2022, PHA served a total of 131 households with its DPL and SPARC programs.

```{r}
#| label: cumulative
#| code-summary: "View code"

# Cumulative total served by program

clients_total <- clients_all |> 
  select(program, close_date_dpl, close_date_spc) |> 
  
  # Collapse close dates into one column
  # Assume DPL close date is correct when SPARC date differs
  
  mutate(close_date = case_when(
    !is.na(close_date_dpl) ~ close_date_dpl,
    TRUE ~ close_date_spc
  ))
  
# Summarise clients by month

clients_cum <- clients_total |> 
  drop_na(close_date) |>     
  count(program, month = floor_date(close_date, "month")) |> 
  ungroup() |> 
  complete(program, month, fill = list(n = 0)) |> 
  
  # Cumulative sum by program
  
  group_by(program) |>
  mutate(cum_sum = cumsum(n))
  
# Create plot

ggplot(clients_cum, aes(x = month, y = cum_sum, fill = program)) +
  geom_area() +
  scale_y_continuous(breaks = c(25,50,75,100,125)) +
  scale_fill_hda() +
  labs(title = "Cumulative total of clients served by program",
       subtitle = "Data from July 2017 through September 2022",
       caption = "**Note:** Four records without close dates are omitted.") +
  theme_hda() +
  add_zero_line("y") +
  theme(
    legend.position = "top"
  )

```

PHA served DPL-only clients from 2017 through 2019, averaging fewer than ten annually. In 2020, PHA began offering SPARC, which has been used by more than 25 clients annually since. Several clients have used both DPL and SPARC assistance each year since 2020.

```{r}
#| label: annual
#| code-summary: "View code"

# Summarise data by program and year

clients_annual <- clients_total |> 
  drop_na(close_date) |>     
  count(program, year = floor_date(close_date, "year")) |> 
  ungroup() |> 
  complete(program, year, fill = list(n = 0)) |> 
  mutate(year = format(year, "%Y"))

# Create plot

ggplot(clients_annual, aes(x = year, y = n, fill = program)) +
  geom_col(position = "stack") +
  scale_fill_hda() +
  labs(title = "Annual number of clients served by program",
       subtitle = "Data from July 2017 through September 2022",
       caption = "**Note:** Four records without close dates are omitted.") +
  theme_hda() +
  add_zero_line("y") +
  theme(
    legend.position = "top"
  )

```

In total, two-thirds (66 percent) of all clients used SPARC only. About one quarter (27 percent) used DPL only, and just eight clients (6 percent) took advantage of both.

```{r}
#| label: totals
#| code-summary: "View code"

# Summarise data by program

clients_program <- clients_total |>     
  count(program)

# Create plot

ggplot(clients_program, aes(y = reorder(program, n), x = n, fill = program, label = n)) +
  geom_col() +
  geom_text(hjust = 2,
            color = "white",
            size = 5) +
  scale_fill_hda() +
  labs(title = "Total number of clients served by program",
       subtitle = "Data from July 2017 through September 2022") +
  theme_hda() +
  add_zero_line("x") +
  flip_gridlines()

```

## Profile of clients

::: {.callout-warning}
Race and ethnicity data is only available for clients who used the DPL program.
:::

Among the 44 clients who used the DPL program, most were white (41 percent) or Black (34 percent). Another 11 percent were Asian, with the remainder being multiracial or of another race. This is a more diverse pattern than Charlottesville as a whole, where 65 percent of residents are white, while only 15 percent of residents are Black, and 9 percent are Asian.

The share of DPL clients who are Hispanic or Latino is about 7 percent, which aligns very closely with the overall population of Charlottesville.

```{r}
#| label: race-ethnicity
#| code-summary: "View code"

# Summarise clients by race

clients_race <- clients_all |> 
  count(race) |> 
  drop_na() |>
  ungroup() |> 
  
  # Add percent column
  
  mutate(pct = n/sum(n)) |> 
  
  # Add source and category columns
  
  mutate(source = "Clients",
         category = "Race",
         .before = 1) |> 
  
  # Update race labels and column names to match ACS data
  
  mutate(race = case_when(
    race == "Black and White" ~ "Multiracial",
    race == "Other races" ~ "Another race",
    TRUE ~ race)) |> 
  rename(label = race,
         value = n)

# Same as above for ethnicity

clients_ethnicity <- clients_all |> 
  count(ethnicity) |> 
  drop_na() |>
  ungroup() |> 
  
  # Add percent column
  
  mutate(pct = n/sum(n)) |> 
  
  # Add source and category columns
  
  mutate(source = "Clients",
         category = "Ethnicity",
         .before = 1) |> 
  
  # Update race labels and column names to match ACS data
  
  mutate(ethnicity = case_when(
    ethnicity == "Hispanic" ~ "Hispanic or Latino",
    ethnicity == "Not Hispanic" ~ "Not Hispanic or Latino",
    TRUE ~ ethnicity)) |> 
  rename(label = ethnicity,
         value = n)

# Add client data to ACS data

race_join <- cv_race |> 
  mutate(source = "Charlottesville", .before = 1) |> 
  bind_rows(clients_race, clients_ethnicity)

race_plot <- race_join |> 
  filter(category == "Race") |> 
  ggplot(aes(x = pct, y = source, fill = reorder(label, pct), alpha = source)) +
    geom_col(position = "stack") +
    scale_fill_hda(-1) +
    scale_alpha_discrete(range = c(0.6, 1)) +
    scale_x_continuous(labels = label_percent()) +
    guides(fill = guide_legend(reverse = TRUE),
           alpha = "none") +
    labs(title = "Client race and ethnicity compared to Charlottesville",
         subtitle = "Includes only DPL clients",
         fill = "Race") +
    theme_hda() +
    flip_gridlines() +
    theme(
      legend.position = "left",
      legend.justification = "left",
      legend.title = element_text(hjust = 0)
    )

ethnicity_plot <- race_join |> 
  filter(category == "Ethnicity") |> 
  ggplot(aes(x = pct, y = source, fill = reorder(label, pct), alpha = source)) +
    geom_col(position = "stack") +
    scale_fill_hda(-1) +
    scale_alpha_discrete(range = c(0.6, 1)) +
    scale_x_continuous(labels = label_percent()) +
    guides(fill = guide_legend(reverse = TRUE),
           alpha = "none") +
    labs(fill = "Ethnicity",
         caption = "**Source:** U.S. Census Bureau, 2020 Decennial Census P.L. 94-171 Redistricting Data.") +
    theme_hda() +
    flip_gridlines() +
    theme(
      legend.position = "left",
      legend.justification = "left",
      legend.title = element_text(hjust = 0)
    )

race_plot + ethnicity_plot +
  plot_layout(ncol = 1)

```

Household incomes are available for 88 of the 131 clients. Of the 43 clients with no income data, all are SPARC-only records. Six of the eight DPL clients who also used SPARC have two incomes recorded for each program---these values all differ, sometimes significantly.

```{r}
#| label: income-data
#| code-summary: "View code"

# Summarise clients by household income

clients_inc <- clients_all |> 
  
  # Select only id_pha, program, and income columns
  
  select(1, 2, 9, 10, 11) |> 
  
  # Combine DLP and SPARC incomes into one column
  
  mutate(income = case_when(
    !is.na(household_annual_income_dpl) & !is.na(household_annual_income_spc) ~ household_annual_income_dpl,
    !is.na(household_annual_income_dpl) & is.na(household_annual_income_spc) ~ household_annual_income_dpl,
    is.na(household_annual_income_dpl) & !is.na(household_annual_income_spc) ~ household_annual_income_spc,
    TRUE ~ NA_real_
  )) |> 
  
  # Add column describing income data availability
  
  mutate(data = case_when(
    !is.na(household_annual_income_dpl) & !is.na(household_annual_income_spc) ~ "Different incomes recorded",
    !is.na(household_annual_income_dpl) & is.na(household_annual_income_spc) ~ "Income recorded",
    is.na(household_annual_income_dpl) & !is.na(household_annual_income_spc) ~ "Income recorded",
    TRUE ~ "No data"
  )) 

# Create plot showing income data availability

clients_inc |> 
  group_by(program, data) |> 
  summarise(n = n()) |> 
  ggplot(aes(x = reorder(program, n, decreasing = TRUE), y = n, fill = data)) +
    geom_col(position = "stack") +
    scale_fill_hda() +
    labs(title = "Client income data availability by program",
         subtitle = "Data from July 2017 through September 2022") +
    theme_hda() +
    add_zero_line("y") +
    theme(
      legend.position = "top"
    )

```

Most of PHA's clients have household incomes between \$25,000 and \$60,000. However, the incomes of SPARC-only clients skew slightly higher, with some above \$75,000.

```{r}
#| label: income-plot
#| code-summary: "View code"

# Summarise income by program

ggplot(clients_inc, aes(x = income, y = program, fill = program)) +
  geom_density_ridges(alpha = 0.9) +
  scale_fill_hda() +
  scale_x_continuous(labels = label_dollar()) +
  labs(title = "Client household income by program",
       subtitle = "Data from July 2017 through September 2022",
       caption = "**Note:** Does not include 43 SPARC clients with no recorded income.") +
  theme_hda() +
  flip_gridlines()

```

Area median incomes (AMI) are calculated only for clients who used the DPL program. AMIs are most commonly between 50 and 80 percent, in line with program eligibility guidelines. On average, AMIs of the DPL clients who also used SPARC are slightly lower than those of clients who used DPL only.

```{r}
#| label: ami
#| code-summary: "View code"

# Summarise AMI by program

clients_inc |> filter(program != "SPARC") |> 
ggplot(aes(x = client_ami, y = program, fill = program)) +
  geom_density_ridges(alpha = 0.9) +
  scale_fill_hda() +
  scale_x_continuous(labels = label_percent(), breaks = c(0, 0.3, 0.5, 0.6, 0.7, 0.8, 1)) +
  labs(title = "Client AMI by program",
       subtitle = "Data from July 2017 through September 2022",
       caption = "**Note:** Does not include 43 SPARC clients with no recorded income.") +
  theme_hda() +
  flip_gridlines()

```

Compared to the distribution of household incomes in Charlottesville, clients are much more likely to earn more than most renters, while still making significantly less than most homeowners. Over 78 percent of clients earn between \$35,000 and \$75,000, versus just 27 percent of renters and 20 percent of homeowners.

```{r}
#| label: income-compare
#| code-summary: "View code"

# Assign client incomes to ACS categories

clients_inc_sum <- clients_inc |> 
  mutate(income = case_when(
    income < 35000 ~ "Less than $35,000",
    income >= 35000 & income < 50000  ~ "$35,000 to $49,999",
    income >= 50000 & income < 75000  ~ "$50,000 to $74,999",
    income >= 75000 & income < 100000  ~ "$75,000 to $99,999",
    income >= 100000 ~ "$100,000 or more",
    TRUE ~ "No data"
  )) |> 
  
  # Filter out clients with no income data (optional)
  
  filter(income != "No data") |>  
  
  # Summarise clients by category
  
  count(income) |> 
  
  # Get column names to match ACS data
  
  mutate(tenure = "Clients", .before = 1) |> 
  rename(estimate = n)

# Join ACS income data with client income data

clients_cv_inc <- clients_inc_sum |> 
  bind_rows(cv_income) |> 
  
  # Add percentages
  
  group_by(tenure) |> 
  mutate(pct = estimate/sum(estimate)) |> 
  
  # Reorder income categories
  
  mutate(income = fct_relevel(
    income, "Less than $35,000", "$35,000 to $49,999", "$50,000 to $74,999",
    "$75,000 to $99,999", "$100,000 or more"))

# Create plot

ggplot(clients_cv_inc, aes(y = pct, x = tenure, fill = tenure)) +
  geom_col() +
  facet_wrap(~income, nrow = 1, labeller = label_wrap_gen(12)) +
  scale_y_continuous(labels = label_percent()) +
  scale_fill_hda() +
  labs(title = "Client income compared to Charlottesville",
       subtitle = "Data from July 2017 through September 2022",
       caption = "**Source:** U.S. Census Bureau, American Community Survey, 2017-2021 5-year estimates. Table B25118.<br>**Note:** Does not include 43 records where client income data not available.") +
  theme_hda() +
  add_zero_line("y") +
  theme(axis.text.x = element_blank(),
        legend.position = "top")

```

## Assistance levels

PHA's DPL program uses funds from a number of different sources. Clients were most commonly supported by HOME funds from DHCD (18) and from Albemarle County's Homebuyer Assistance Program (11). Overall, PHA has used eight separate sources to fund its DPL program.

```{r}
#| label: dpl-sources
#| code-summary: "View code"

dpl_sources <- clients_all |> 
  filter(program != "SPARC") |> 
  select(1, 2, 36:43) |> 
  pivot_longer(
    cols = c(3:10),
    names_to = "source",
    values_to = "x"
  ) |> 
  group_by(source) |> 
  summarise(count = sum(x)) |> 
  mutate(source = case_when(
    source == "dhcd" ~ "DHCD HOME",
    source == "achap" ~ "Albemarle County HAP",
    source == "cdfi" ~ "CDFI Regional Down-payment Loan Program",
    source == "recycled_home" ~ "Recycled HOME",
    source == "cahf" ~ "Charlottesville Affordable Housing Fund",
    source == "city" ~ "Charlottesville HOME",
    source == "pha_regional" ~ "PHA Regional Homeownership Fund",
    source == "lchap" ~ "Louisa County HAP",
    TRUE ~ str_to_upper(source)
  )) |> 
  mutate(source = str_wrap(source, 20))

ggplot(dpl_sources, aes(x = count, y = reorder(source, count), label = count)) + 
  geom_col(fill = "#445ca9") +
  geom_text(color = "#FFFFFF", nudge_x = -0.5) +
  theme_hda() +
  flip_gridlines() +
  add_zero_line("x") +
  labs(
    title = "Number of DPL awards by source",
    subtitle = "Data from July 2017 through September 2022",
    caption = "**Notes:** 'HAP' = Homebuyer Assistance Program."
  )

```

PHA awarded a total of \$1,242,190 in DPL assistance from July 2017 to September 2022. This amounted to roughly \$28,230 provided per client.

```{r}
#| label: dpl-amount
#| code-summary: "View code"

dpl_amount <- clients_all |> 
  drop_na("close_date_dpl") |> 
  arrange(close_date_dpl) |> 
  mutate(cum_sum = cumsum(pha_loans_amount))

ggplot(dpl_amount, aes(x = close_date_dpl, y = cum_sum)) +
  geom_area(fill = "#445ca9") +
  scale_y_continuous(labels = label_dollar(scale = 0.001, suffix = "k")) +
  add_zero_line("y") +
  theme_hda() +
  labs(
    title = "Total amount of DPL assistance awarded",
    subtitle = "Data from July 2017 through September 2022"
  )
  
```

The average amount each client received stayed around \$28,000 from 2017 through 2020. In 2021, that average increased to \$37,435. In 2022, the two clients that received DPL each received significant DPL assistance well above prior year averages.

```{r}
#| label: dpl-annual
#| code-summary: "View code"

dpl_annual <- dpl_amount |> 
  mutate(year = format(close_date_dpl, format = "%Y")) |> 
  filter(pha_loans_amount != 0) |> 
  group_by(year) |> 
  summarise(avg = mean(pha_loans_amount),
            clients = n())

ggplot(dpl_annual, aes(x = year, y = avg, label = clients)) +
  geom_col(fill = "#445ca9") +
  geom_text(vjust = 2,
            color = "white",
            size = 5) +
  annotate("text", x = 2.25, y = 55000, label = "Bars show total number of clients for that year",
           color = "#445ca9", size = 5) +
  scale_y_continuous(labels = label_dollar(scale = 0.001, suffix = "k"),
                     breaks = c(10000, 20000, 30000, 40000, 50000)) +
  add_zero_line("y") +
  theme_hda() +
  labs(
    title = "Average amount of DPL assistance awarded per client",
    subtitle = "Data from July 2017 through September 2022"
  )

```

Black clients were the only race with an average DPL amount (\$20,761) below the overall average. Asian, Black and White, and White-alone clients all had averages between \$32,000 and \$34,000. Three clients of another race tallied a notably higher average at \$42,973.

```{r}
#| label: dpl-race
#| code-summary: "View code"

dpl_race <- dpl_amount |> 
  filter(pha_loans_amount != 0) |> 
  group_by(race) |> 
  summarise(avg = mean(pha_loans_amount),
            clients = n())

ggplot(dpl_race, aes(x = reorder(race, avg), y = avg, fill = race, label = clients)) +
  geom_col() +
  geom_text(vjust = 2,
            color = "white",
            size = 5) +
  scale_fill_hda() +
  scale_y_continuous(labels = label_dollar(scale = 0.001, suffix = "k"),
                     breaks = c(10000, 20000, 30000, 40000, 50000)) +
  add_zero_line("y") +
  theme_hda() +
  labs(
    title = "Average amount of DPL assistance awarded by race",
    subtitle = "Data from July 2017 through September 2022",
    caption = "**Note:** Bars show total number of clients for that group."
  )

```

Only five total clients were Hispanic or chose not to respond when asked their ethnicity. As a result, the average DPL amount for non-Hispanic clients (\$29,310) is very close to the overall client average. Among the three clients who were Hispanic, their average DPL amounted to a much larger \$42,316.

```{r}
#| label: dpl-ethnicity
#| code-summary: "View code"

dpl_ethnicity <- dpl_amount |> 
  filter(pha_loans_amount != 0) |> 
  group_by(ethnicity) |> 
  summarise(avg = mean(pha_loans_amount),
            clients = n())

ggplot(dpl_ethnicity, aes(x = reorder(ethnicity, avg), y = avg, fill = ethnicity, label = clients)) +
  geom_col() +
  geom_text(vjust = 2,
            color = "white",
            size = 5) +
  scale_fill_hda() +
  scale_y_continuous(labels = label_dollar(scale = 0.001, suffix = "k"),
                     breaks = c(10000, 20000, 30000, 40000, 50000)) +
  add_zero_line("y") +
  theme_hda() +
  labs(
    title = "Average amount of DPL assistance awarded by ethnicity",
    subtitle = "Data from July 2017 through September 2022",
    caption = "**Note:** Bars show total number of clients for that group."
  )

```

## Spatial patterns

```{r}
# Locations of prior client home
# Locations of home purchased by client
```

## Housing outcomes

...

```{r}
#| label: price-table
#| code-summary: "View code"

# Summarise home sales price by program

clients_inc_price <- clients_all |> 

  # Select only id_pha, program, income, and home sales price columns
  
  select(1, 2, 9, 10, 20, 21) |>
  
  # Combine DLP and SPARC incomes into one column
  
  mutate(income = case_when(
    !is.na(household_annual_income_dpl) & !is.na(household_annual_income_spc) ~ household_annual_income_dpl,
    !is.na(household_annual_income_dpl) & is.na(household_annual_income_spc) ~ household_annual_income_dpl,
    is.na(household_annual_income_dpl) & !is.na(household_annual_income_spc) ~ household_annual_income_spc,
    TRUE ~ NA_real_
  )) |> 

  # Combine DLP and SPARC sales prices into one column
  
  mutate(price = case_when(
    !is.na(sale_price_dpl) ~ sale_price_dpl,
    TRUE ~ sale_price_spc
  ))

# Generate table

clients_inc_price |> 
  drop_na(price) |> 
  group_by(program) |> 
  summarise(n = n(),
            price = median(price)) |> 
  mutate(price = formattable::currency(price, digits = 0)) |> 
  arrange(desc(price)) |> 
  kable(col.names = c("Program", "Clients", "Median sales price")) |> 
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  )

```

...

```{r}
#| label: price-plot
#| code-summary: "View code"

ggplot(clients_inc_price, aes(x = price, y = program, fill = program)) +
  geom_density_ridges(alpha = 0.9) +
  scale_fill_hda() +
  scale_x_continuous(labels = label_dollar(),
                     limits = c(75000, 350000),
                     breaks = c(100000, 150000, 200000, 250000, 300000)) +
  labs(title = "Client home purchase price by program",
       subtitle = "Data from July 2017 through September 2022") +
  theme_hda() +
  flip_gridlines()

```

```{r}
# Client home attributes and price compared to neighborhood
# Client loan products compared to region (and neighborhood, if possible)
```

## Home equity

```{r}
# Two methods to try and test

# Option 1:
# Find average percent change in assessment values from purchase date to current for all comparable homes in neighborhood
# Apply percent change to original sales price for estimated home value
# Calculate remaining mortgage balance using loan info
# value - balance = equity

# Option 2:
# Same as above but use MLS sales data
# Will have much smaller sample size -- may only be possible at city level
# Determine if any past clients have already sold home -- would provide most accurate estimate
```

# Takeaways

`Major (and other noteworthy) findings from analysis`

# Next steps

HDAdvisors will continue to work with PHA on the following next steps:

* Develop consistent data entry/collection procedures to reduce time needed for data cleaning/correction in future analysis.
* Collect and analyze program application data for clients who did not receive assistance from DPL and/or SPARC. Assess, if possible, reasons for denial and compare with loan denial trends in HMDA data.

`Plenty more to add here`

